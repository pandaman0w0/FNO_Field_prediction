{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWha_PqC0yPq"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2N_1VSk0y8e"
   },
   "outputs": [],
   "source": [
    "def activation(name):\n",
    "    if name in ['tanh', 'Tanh']:\n",
    "        return nn.Tanh()\n",
    "    elif name in ['relu', 'ReLU']:\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif name in ['lrelu', 'LReLU']:\n",
    "        return nn.LeakyReLU(inplace=True)\n",
    "    elif name in ['sigmoid', 'Sigmoid']:\n",
    "        return nn.Sigmoid()\n",
    "    elif name in ['softplus', 'Softplus']:\n",
    "        return nn.Softplus(beta=4)\n",
    "    elif name in ['celu', 'CeLU']:\n",
    "        return nn.CELU()\n",
    "    elif name in ['elu']:\n",
    "        return nn.ELU()\n",
    "    elif name in ['mish']:\n",
    "        return nn.Mish()\n",
    "    else:\n",
    "        raise ValueError('Unknown activation function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoE-NaIN00GF"
   },
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  \n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O7_8o9S063x"
   },
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, fno_architecture, device=None, padding_frac=1 / 4):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        self.modes1 = fno_architecture[\"modes\"]\n",
    "        self.modes2 = fno_architecture[\"modes\"]\n",
    "        self.width = fno_architecture[\"width\"]\n",
    "        self.n_layers = fno_architecture[\"n_layers\"]\n",
    "        self.retrain_fno = fno_architecture[\"retrain_fno\"]\n",
    "\n",
    "        torch.manual_seed(self.retrain_fno)\n",
    "        # self.padding = 9 # pad the domain if input is non-periodic\n",
    "        self.padding_frac = padding_frac\n",
    "        self.fc0 = nn.Linear(3, self.width)  # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv_list = nn.ModuleList(\n",
    "            [nn.Conv2d(self.width, self.width, 1) for _ in range(self.n_layers)])\n",
    "        self.spectral_list = nn.ModuleList(\n",
    "            [SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(self.n_layers)])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x1_padding = int(round(x.shape[-1] * self.padding_frac))\n",
    "        x2_padding = int(round(x.shape[-2] * self.padding_frac))\n",
    "        x = F.pad(x, [0, x1_padding, 0, x2_padding])\n",
    "\n",
    "        for k, (s, c) in enumerate(zip(self.spectral_list, self.conv_list)):\n",
    "\n",
    "            x1 = s(x)\n",
    "            x2 = c(x)\n",
    "            x = x1 + x2\n",
    "            if k != self.n_layers - 1:\n",
    "                x = F.gelu(x)\n",
    "        x = x[..., :-x1_padding, :-x2_padding]\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyWnex8409g_"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_2Qbk6D0_Ps"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1733115029249,
     "user": {
      "displayName": "pan pan",
      "userId": "13937346862066559159"
     },
     "user_tz": 300
    },
    "id": "TcFYngPK1ys5",
    "outputId": "ec7e919c-fff3-4f8b-8062-0ef9866e5435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1733115029552,
     "user": {
      "displayName": "pan pan",
      "userId": "13937346862066559159"
     },
     "user_tz": 300
    },
    "id": "vAZutcRl1AqK",
    "outputId": "ad56cf9b-d048-4145-fa9b-fc60b16dfc46"
   },
   "outputs": [],
   "source": [
    "#conventional training method\n",
    "input_tensor = torch.load('filedirectory/input_tensor.pt')\n",
    "output_tensor = torch.load('filedirectory/output_tensor.pt')\n",
    "print(f'Input tensor shape: {input_tensor.shape}')\n",
    "print(f'Output tensor shape: {output_tensor.shape}')\n",
    "dataset = TensorDataset(input_tensor, output_tensor)\n",
    "\n",
    "# splitting data\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "training_set, testing_set = random_split(dataset, [train_size, test_size])\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testing_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1733115050503,
     "user": {
      "displayName": "pan pan",
      "userId": "13937346862066559159"
     },
     "user_tz": 300
    },
    "id": "fwSA1WX1sWX4",
    "outputId": "ab4d30f2-5da7-416e-c51f-12c6d5179c3d"
   },
   "outputs": [],
   "source": [
    "input_tensor_test = torch.load('filedirectory/input_tensor_test.pt')\n",
    "output_tensor_test = torch.load('filedirectory/output_tensor_test.pt')\n",
    "\n",
    "original_size = input_tensor_test.shape[0]\n",
    "print(f\"Original dataset size: {original_size}\")\n",
    "\n",
    "max_values = input_tensor_test.view(original_size, -1).max(dim=1)[0]\n",
    "\n",
    "filter_condition = max_values > 1.5\n",
    "filtered_input_tensor = input_tensor_test[filter_condition]\n",
    "filtered_output_tensor = output_tensor_test[filter_condition]\n",
    "\n",
    "filtered_size = filtered_input_tensor.shape[0]\n",
    "\n",
    "replication_factor = original_size // filtered_size  \n",
    "expanded_input_tensor = filtered_input_tensor.repeat(replication_factor, 1, 1, 1)[:original_size]\n",
    "expanded_output_tensor = filtered_output_tensor.repeat(replication_factor, 1,1,1)[:original_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWdKMwYAs7D4"
   },
   "outputs": [],
   "source": [
    "input_tensor_test = expanded_input_tensor\n",
    "output_tensor_test = expanded_output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733115061450,
     "user": {
      "displayName": "pan pan",
      "userId": "13937346862066559159"
     },
     "user_tz": 300
    },
    "id": "Pe0a9CCGRT-E",
    "outputId": "bda6e4a0-aece-426f-87e1-e70a8e5fc40c"
   },
   "outputs": [],
   "source": [
    "#curriculum training\n",
    "batch_size = 2\n",
    "#input_tensor_test = torch.load('/content/drive/My Drive/Colab Notebooks/input_tensor_test.pt')\n",
    "#output_tensor_test = torch.load('/content/drive/My Drive/Colab Notebooks/output_tensor_test.pt')\n",
    "\n",
    "test_dataset = TensorDataset(input_tensor_test, output_tensor_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "group_ids = [1, 2, 3, 4] \n",
    "group_dataloaders = {}\n",
    "\n",
    "for group_id in group_ids:\n",
    "    input_group_file = f'filedirectory/input_group_{group_id}.pt'\n",
    "    output_group_file = f'filedirectory/output_group_{group_id}.pt'\n",
    "\n",
    "    input_group = torch.load(input_group_file)\n",
    "    output_group = torch.load(output_group_file)\n",
    "\n",
    "    group_dataset = TensorDataset(input_group, output_group)\n",
    "    group_loader = DataLoader(group_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    group_dataloaders[group_id] = group_loader\n",
    "\n",
    "print('Grouped data loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8leMdgEI2o1i"
   },
   "outputs": [],
   "source": [
    "fno_architecture = {\n",
    "    \"modes\": 32,\n",
    "    \"width\": 64,\n",
    "    \"n_layers\": 12,\n",
    "    \"retrain_fno\": 42\n",
    "}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fno = FNO2d(fno_architecture, device=device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "epochs_per_group = 250\n",
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3440794,
     "status": "ok",
     "timestamp": 1733118505601,
     "user": {
      "displayName": "pan pan",
      "userId": "13937346862066559159"
     },
     "user_tz": 300
    },
    "id": "gM_TO6mZ2vSe",
    "outputId": "30bee4aa-eb06-48ce-a890-8e0de93e466d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train Loss: 764.497607, Relative L2 Test Error: 44.33%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_50.pth\n",
      "Epoch: 100, Train Loss: 723.324500, Relative L2 Test Error: 48.05%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_100.pth\n",
      "Epoch: 150, Train Loss: 387.217780, Relative L2 Test Error: 48.10%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_150.pth\n",
      "Epoch: 200, Train Loss: 209.936261, Relative L2 Test Error: 49.85%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_200.pth\n",
      "Epoch: 250, Train Loss: 203.904416, Relative L2 Test Error: 50.40%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_250.pth\n",
      "Epoch: 300, Train Loss: 212.984919, Relative L2 Test Error: 37.23%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_300.pth\n",
      "Epoch: 350, Train Loss: 188.862432, Relative L2 Test Error: 38.03%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_350.pth\n",
      "Epoch: 400, Train Loss: 181.717896, Relative L2 Test Error: 38.45%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_400.pth\n",
      "Epoch: 450, Train Loss: 178.938029, Relative L2 Test Error: 38.60%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_450.pth\n",
      "Epoch: 500, Train Loss: 177.680801, Relative L2 Test Error: 38.69%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_500.pth\n",
      "Epoch: 550, Train Loss: 354.285258, Relative L2 Test Error: 40.56%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_550.pth\n",
      "Epoch: 600, Train Loss: 342.304769, Relative L2 Test Error: 40.29%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_600.pth\n",
      "Epoch: 650, Train Loss: 337.214895, Relative L2 Test Error: 40.19%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_650.pth\n",
      "Epoch: 700, Train Loss: 334.851746, Relative L2 Test Error: 40.14%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_700.pth\n",
      "Epoch: 750, Train Loss: 333.722382, Relative L2 Test Error: 40.11%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_750.pth\n",
      "Epoch: 800, Train Loss: 389.460846, Relative L2 Test Error: 39.93%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_800.pth\n",
      "Epoch: 850, Train Loss: 388.666931, Relative L2 Test Error: 39.86%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_850.pth\n",
      "Epoch: 900, Train Loss: 388.320374, Relative L2 Test Error: 39.83%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_900.pth\n",
      "Epoch: 950, Train Loss: 388.165914, Relative L2 Test Error: 39.81%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_950.pth\n",
      "Epoch: 1000, Train Loss: 388.102763, Relative L2 Test Error: 39.81%\n",
      "Model saved to /content/drive/My Drive/Colab Notebooks/saved_models_step/fno_epoch_1000.pth\n",
      "Training losses saved to /content/drive/My Drive/Colab Notebooks/training_logs_step/train_losses.pt\n",
      "Test errors saved to /content/drive/My Drive/Colab Notebooks/training_logs_step/test_errors.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 50\n",
    "freq_print = n\n",
    "num_groups = 4\n",
    "model_save_dir = 'filedirectory/saved_models_step'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "log_save_dir = 'filedirectory/training_logs_step'\n",
    "os.makedirs(log_save_dir, exist_ok=True)\n",
    "\n",
    "train_losses = []\n",
    "test_errors = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    group_index = epoch // epochs_per_group\n",
    "    if group_index >= num_groups:\n",
    "        group_index = num_groups - 1\n",
    "    current_group_id = group_ids[group_index]\n",
    "    train_loader = group_dataloaders[current_group_id]\n",
    "\n",
    "    fno.train()\n",
    "    train_mse = 0.0\n",
    "    for step, (input_batch, output_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_batch = input_batch.to(device)\n",
    "        output_batch = output_batch.to(device)\n",
    "\n",
    "        output_pred_batch = fno(input_batch)\n",
    "\n",
    "        loss = criterion(output_pred_batch, output_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_mse += loss.item()\n",
    "\n",
    "    train_mse /= len(train_loader)\n",
    "    train_losses.append(train_mse)\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fno.eval()\n",
    "        test_relative_l2 = 0.0\n",
    "        for step, (input_batch, output_batch) in enumerate(test_loader):\n",
    "            input_batch = input_batch.to(device)\n",
    "            output_batch = output_batch.to(device)\n",
    "\n",
    "            output_pred_batch = fno(input_batch)\n",
    "            loss_rel = (torch.mean((output_pred_batch - output_batch) ** 2) / torch.mean(output_batch ** 2)).sqrt() * 100\n",
    "            test_relative_l2 += loss_rel.item()\n",
    "\n",
    "        test_relative_l2 /= len(test_loader)\n",
    "        test_errors.append(test_relative_l2)\n",
    "\n",
    "    if (epoch + 1) % freq_print == 0:\n",
    "        print(f\"Epoch: {epoch + 1}, Train Loss: {train_mse:.6f}, Relative L2 Test Error: {test_relative_l2:.2f}%\")\n",
    "        model_filename = f'fno_epoch_{epoch + 1}.pth'\n",
    "        model_path = os.path.join(model_save_dir, model_filename)\n",
    "        torch.save(fno.state_dict(), model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "\n",
    "train_losses_path = os.path.join(log_save_dir, 'train_losses.pt')\n",
    "torch.save(train_losses, train_losses_path)\n",
    "\n",
    "test_errors_path = os.path.join(log_save_dir, 'test_errors.pt')\n",
    "torch.save(test_errors, test_errors_path)\n",
    "\n",
    "print(f\"Training losses saved to {train_losses_path}\")\n",
    "print(f\"Test errors saved to {test_errors_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nB8Gxrjt2zZP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO9XVW/54koIC1fgKN+4PrO",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
